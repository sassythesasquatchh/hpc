
The following have been reloaded with a version change:
  1) gcc/4.8.5 => gcc/11.4.0

-------------------------------------------------------------
STREAM version $Revision: 5.10 $
-------------------------------------------------------------
This system uses 8 bytes per array element.
-------------------------------------------------------------
Array size = 16000000 (elements), Offset = 0 (elements)
Memory per array = 122.1 MiB (= 0.1 GiB).
Total memory required = 366.2 MiB (= 0.4 GiB).
Each kernel will be executed 20 times.
 The *best* time for each kernel (excluding the first iteration)
 will be used to compute the reported bandwidth.
-------------------------------------------------------------
Your clock granularity/precision appears to be 1 microseconds.
Each test below will take on the order of 6702 microseconds.
   (= 6702 clock ticks)
Increase the size of the arrays if this shows that
you are not getting at least 20 clock ticks per test.
-------------------------------------------------------------
WARNING -- The above is only a rough guideline.
For best results, please be sure you know the
precision of your system timer.
-------------------------------------------------------------
Function    Best Rate MB/s  Avg time     Min time     Max time
Copy:           36235.9     0.007355     0.007065     0.007691
Scale:          25189.8     0.010366     0.010163     0.010624
Add:            26131.5     0.015111     0.014695     0.015696
Triad:          26526.6     0.014872     0.014476     0.015407
-------------------------------------------------------------
Solution Validates: avg error less than 1.000000e-13 on all three arrays
-------------------------------------------------------------
